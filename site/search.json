{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"IOC Cleanup","text":"<p><code>ioc_cleanup</code> provides a reproducible, transparent, and traceable workflow for cleaning tide gauge data from IOC (Intergovernmental Oceanographic Commission) stations worldwide.</p>","path":["IOC Cleanup"],"tags":[]},{"location":"#ioc-cleanup-database","level":2,"title":"IOC Cleanup database","text":"<p>All stations with clean data between 1st of January 2020 and the 31st of december 2025.</p> <p> </p>","path":["IOC Cleanup"],"tags":[]},{"location":"#getting-started","level":2,"title":"Getting Started","text":"","path":["IOC Cleanup"],"tags":[]},{"location":"#prerequisites","level":3,"title":"Prerequisites","text":"<ul> <li>Python 3.11+ (recommended)</li> <li>~24 GB free disk space for raw IOC 2020-2025 data</li> </ul>","path":["IOC Cleanup"],"tags":[]},{"location":"#installation","level":3,"title":"Installation","text":"<pre><code>git clone https://github.com/seareport/ioc_cleanup.git\npip install -r requirements.txt\n</code></pre>","path":["IOC Cleanup"],"tags":[]},{"location":"#minimal-example","level":3,"title":"Minimal example","text":"<pre><code>import searvey\nimport ioc_cleanup as C\n\nstation = \"abed\"\ndf_raw = searvey.fetch_ioc_station(station, \"2020-01-01\", \"2026-01-01\")\n\ntrans = C.load_transformation_from_path(\n    \"../transformations/abed_bub.json\"\n)\n\ndf_clean = C.transform(df_raw, trans)\n</code></pre>","path":["IOC Cleanup"],"tags":[]},{"location":"#example-for-maya-station","level":2,"title":"Example for <code>maya</code> station:","text":"","path":["IOC Cleanup"],"tags":[]},{"location":"#from-raw-signal","level":3,"title":"From raw signal...","text":"<p>... using JSON transformation ...</p>","path":["IOC Cleanup"],"tags":[]},{"location":"#to-clean-signal","level":3,"title":"... to clean signal","text":"","path":["IOC Cleanup"],"tags":[]},{"location":"concept/","level":1,"title":"Motivation","text":"<p>Cleaning tide gauge data is often:</p> <ul> <li> manual</li> <li> poorly documented</li> <li> hard to reproduce</li> <li> difficult to review or share</li> </ul> <p><code>ioc_cleanup</code> concept:</p> <p>This project proposes a community-driven, version-controlled     approach where all cleaning decisions are explicitly recorded and auditable.</p>","path":["Motivation"],"tags":[]},{"location":"concept/#concept","level":2,"title":"Concept","text":"<p>The core idea of <code>ioc_cleanup</code> is declarative cleaning.</p> <p>Instead of scripts or notebooks, all cleaning decisions are:</p> <ul> <li> Explicit</li> <li> Version controlled</li> <li> Human-readable</li> <li> Reviewable</li> </ul> <p>Cleaning logic lives entirely in JSON files.</p>","path":["Motivation"],"tags":[]},{"location":"concept/#why-it-matters","level":2,"title":"Why it matters","text":"<p>This methodology allows:</p> <ul> <li> Flagging:<ul> <li>bad or corrupt data (timestamp / data ranges)</li> <li>sensor breakpoints</li> <li>singular phenomena (e.g. tsunamis, meteo-tsunamis, seiches, or unidentified events)</li> </ul> </li> <li> Reproducible cleaning</li> <li> Transparent and traceable decisions stored in plain JSON</li> <li> Peer review of cleaning decisions via GitHub</li> <li> Easy extension to any other datasets (e.g. GESLA, NDBC)</li> <li> Gradual growth in station coverage through community contributions</li> </ul>","path":["Motivation"],"tags":[]},{"location":"concept/#transformations","level":2,"title":"Transformations","text":"<p>Each station/sensor pair is described by a JSON file located in:</p> <pre><code>./transformations/\n</code></pre> <p>These files define the transformation from raw data → clean signal by declaring:</p> <ul> <li>valid time windows</li> <li>dropped timestamps</li> <li>dropped ranges</li> <li>breakpoints</li> <li>notes and metadata</li> </ul> <p>More details in the JSON format</p>","path":["Motivation"],"tags":[]},{"location":"contributing/","level":1,"title":"Contributing","text":"<p>Contributions are very welcome!</p>","path":["Contributing"],"tags":[]},{"location":"contributing/#how-to-contribute","level":2,"title":"How to contribute","text":"<ol> <li>Fork the repository</li> <li>Add or update a JSON transformation file</li> <li>Use the dashboard to clean or flag data</li> <li>Submit a pull request with a clear description of your changes</li> </ol>","path":["Contributing"],"tags":[]},{"location":"contributing/#areas-for-improvement","level":2,"title":"Areas for improvement","text":"<ul> <li>Publication and doi for clean dataset (WIP)</li> <li>Add more IOC stations</li> <li>Extend the cleaned time range (currently 2020–2025)</li> </ul>","path":["Contributing"],"tags":[]},{"location":"limitations/","level":1,"title":"Caveats and limitations","text":"<p>Please be aware of the following:</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#download-data-yourself","level":2,"title":"Download data yourself","text":"<p>This repository does NOT contain IOC data and does not manage data acquisition.</p> <ul> <li>Data download is not handled internally</li> <li>Examples (in this <code>README</code> or in <code>tests</code>) use the <code>searvey</code> package</li> <li>A release of cleaned data through Zenodo is considered (although not planned yet)</li> </ul>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#cleaning-is-difficult-examples","level":2,"title":"Cleaning is difficult - Examples","text":"<p>In some cases, cleaning is easy and is just about removing spikes</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#spikes","level":3,"title":"Spikes","text":"<p>Advice for Spikes</p> <p>Remove all spikes selected by copying all timestamps in the <code>dropped_timestamps: []</code> array in the JSON file.</p> <p>See details on the JSON structure</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#noise-vs-physical-phenomena","level":3,"title":"Noise vs. Physical phenomena","text":"<p>It becomes more difficult when it comes to distinguishing noise (either numerical or physical e.g. boat wakes) from real physical events (like harbour seiches or tsunamis).</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#physical-seiches","level":4,"title":"Physical - Seiches","text":"<p>Here an example of what seems to be a harbour seiche in <code>LA23</code> - Lampedusa station (IT):</p> <p> </p> <p>Advice for Seiches</p> <p>Do nothing</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#physical-tsunamis","level":4,"title":"Physical - Tsunamis","text":"<p>Here is the 2025 Kamchatka Peninsula Tsunami captured by <code>cres</code> - Crescent City station (CA, USA):</p> <p> </p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#physical-tsunamis-de-tided","level":4,"title":"Physical - Tsunamis (de-tided)","text":"<p>Same tsunami and station, detided:</p> <p> </p> <p>Advice for Tsunamis</p> <p>Use the selection box to get the tsunami time range and copy it in the <code>tsunami: []</code> array in the JSON file.</p> <p>See details on the JSON structure</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#noise-numerical","level":4,"title":"Noise - Numerical","text":"<p>In some case, numerical noise is easy to isolate like for this station:</p> <p> </p> <p>Advice for Noise</p> <p>When you're confident about the noise nature, use the selection box to select either time steps or time ranges and paste them in <code>dropped_date_ranges</code> or <code>dropped_timestamps</code> depending on the case.</p> <p>See details on the JSON structure</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#noise-unknown","level":4,"title":"Noise - Unknown","text":"<p>In other case, the nature of the noise is difficult to identify. There could be lots of reasons:</p> <ul> <li>physical induced noise:<ul> <li>wakes from boats passing in the vicinity of the station</li> <li>seiches (or surfbeat) of shorter period than the sampling frequency</li> <li>waves affecting directly the sensor</li> </ul> </li> <li>numerical-induced noise<ul> <li>station not well calibrated</li> <li>more unknown reasons</li> </ul> </li> </ul>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#example-1","level":5,"title":"Example 1","text":"","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#example-2","level":5,"title":"Example 2","text":"<p>Advice for Noise</p> <p>When you're NOT confident about the noise nature, do nothing</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#steps","level":3,"title":"Steps","text":"","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#steps-short-dst","level":4,"title":"Steps - Short (DST)","text":"<p>Some steps are easy to isolate and deal with. A recurrent error found on tidal stations occurs during DST (Daylight saving time) changes:</p> <p> </p> <p>Advice for short steps segments</p> <p>When the step is short, you can use the box select tool to get the time range of the step and paste it in <code>dropped_date_ranges</code>.</p> <p>See details on the JSON structure</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#steps-long","level":4,"title":"Steps - Long","text":"<p>Some steps - or offsets - can be caused by mulitple reasons:</p> <ul> <li>a sensor change</li> <li>a re-calibration</li> <li>any ohter unkonwn reason</li> </ul> <p> </p> <p>Advice for long steps segments</p> <p>When the step is a long - years spanning - segment, select one time step between the break and add it to the <code>breakpoints: []</code> array in the JSON file. For the above example we have : <pre><code>\"breakpoints\": [\n  \"2023-07-05T07:47:00\"\n],\n</code></pre></p> <p>See details on the JSON structure</p> <p>Warning</p> <p>We don't provide any fix for steps or offsets in the data.</p> <p>The <code>ioc_cleanup.clean()</code> does not demean any part of the signal.</p> <p>In the dashboard, we demean signal between breakpoints just for the ease of visualization (more details in <code>ioc_cleanup._tools</code>).</p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#vertical-datum","level":3,"title":"Vertical datum","text":"<p>Warning</p> <p>Vertical datum are not yet corrected in <code>ioc_cleanup</code>.</p> <p>It is unclear how local data providers have set-up their sensor calibration and if they all respect local vertical datum conventions.</p> <p>A interesting lead would be in using the PSMSL (Permanent Service for Mean Sea Level) data available at least for all GLOSS stations:</p> <p></p>","path":["Caveats and limitations"],"tags":[]},{"location":"limitations/#subjectivity","level":3,"title":"Subjectivity","text":"<p>Warning</p> <ul> <li>Cleaning decisions are inherently subjective</li> <li>Different operators may disagree on what should be discarded</li> </ul>","path":["Caveats and limitations"],"tags":[]},{"location":"reference/data-layout/","level":1,"title":"Data layout","text":"<p>IOC data is archived by year:</p> <pre><code>./data/\n├── 2020\n├── 2021\n├── 2022\n├── 2023\n├── 2024\n└── 2025\n</code></pre> <p>This structure allows scalable extension to additional years.</p>","path":["Reference","Data layout"],"tags":[]},{"location":"reference/data-layout/#naming-convention","level":2,"title":"Naming convention","text":"<p>The JSON files adopts the following naming convention:</p> <pre><code>./transformations/&lt;ioc_code&gt;_&lt;sensor&gt;.json\n</code></pre>","path":["Reference","Data layout"],"tags":[]},{"location":"reference/data-layout/#usage","level":2,"title":"Usage","text":"<p>Using the function <code>download_year_station()</code> will put the raw data directly in the data tree.</p> <p>for example this function:</p> <pre><code>import ioc_cleanup as C\nioc_all = C.get_meta()\nyear = 2025\nfor station in ioc_all.ioc_code.tolist():\n  C.download_year_station(station, year, data_folder=\"../data\")\n</code></pre> <p>downloads all IOC stations data for 2025 as Parquet files into:</p> <pre><code>./data/\n└── 2025\n</code></pre>","path":["Reference","Data layout"],"tags":[]},{"location":"reference/json-schema/","level":1,"title":"Transformation JSON schema","text":"","path":["Reference","Transformation JSON schema"],"tags":[]},{"location":"reference/json-schema/#example","level":2,"title":"Example","text":"<pre><code>{\n  \"ioc_code\": \"abed\",\n  \"sensor\": \"bub\",\n  \"notes\": \"\",\n  \"skip\": false,\n  \"wip\": false,\n  \"start\": \"2020-01-01T00:00:00\",\n  \"end\": \"2026-01-01T00:00:00\",\n  \"high\": null,\n  \"low\": null,\n  \"dropped_date_ranges\": [\n    [\"2022-03-27 03:00:00\", \"2022-03-27 03:45:00\"],\n    [\"2023-03-26 03:00:00\", \"2023-03-26 03:45:00\"]\n  ],\n  \"dropped_timestamps\": [\n    \"2022-09-30T14:45:00\",\n    \"2022-09-30T15:30:00\",\n    \"2022-10-02T06:45:00\",\n    \"2022-10-02T07:00:00\",\n    \"2023-06-21T00:15:00\",\n    \"2024-04-24T11:00:00\",\n    \"2024-09-07 12:00:00\"\n  ],\n  \"breakpoints\": [],\n  \"tsunami\": []\n}\n</code></pre>","path":["Reference","Transformation JSON schema"],"tags":[]},{"location":"reference/json-schema/#field-descriptions","level":2,"title":"Field descriptions","text":"Field Description <code>ioc_code</code> IOC station code <code>sensor</code> Sensor identifier <code>start</code>, <code>end</code> Valid data window <code>dropped_date_ranges</code> Continuous ranges to remove <code>dropped_timestamps</code> Individual timestamps <code>breakpoints</code> Sensor regime changes <code>tsunami</code> Eventual tsunami(s) date ranges <code>skip</code> Ignore station <code>wip</code> Work in progress","path":["Reference","Transformation JSON schema"],"tags":[]},{"location":"reference/python-api/","level":1,"title":"Python API","text":"<p>This page documents the public Python API of <code>ioc_cleanup</code>. Only stable, user-facing functions are listed here.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#transformations-cleaning","level":2,"title":"Transformations &amp; Cleaning","text":"<p>Functions related to loading, applying, and managing cleaning transformations.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.load_transformation","level":3,"title":"<code>ioc_cleanup.load_transformation(ioc_code, sensor, src_dir=_constants.TRANSFORMATIONS_DIR)</code>","text":"<p>Load a transformation definition for a station and sensor.</p> <p>This is a convenience wrapper around <code>load_transformation_from_path</code> that constructs the transformation filename from the IOC station code and sensor identifier.</p> <p>Parameters:</p> Name Type Description Default <code>ioc_code</code> <code>str</code> <p>IOC station code.</p> required <code>sensor</code> <code>str</code> <p>Sensor identifier.</p> required <code>src_dir</code> <code>str | PathLike[str]</code> <p>Directory containing transformation JSON files.</p> <code>TRANSFORMATIONS_DIR</code> <p>Returns:</p> Type Description <code>Transformation</code> <p>Parsed transformation model.</p> Source code in <code>ioc_cleanup/_tools.py</code> <pre><code>def load_transformation(\n    ioc_code: str,\n    sensor: str,\n    src_dir: str | os.PathLike[str] = _constants.TRANSFORMATIONS_DIR,\n) -&gt; _models.Transformation:\n    \"\"\"\n    Load a transformation definition for a station and sensor.\n\n    This is a convenience wrapper around\n    `load_transformation_from_path` that constructs the transformation\n    filename from the IOC station code and sensor identifier.\n\n    Args:\n        ioc_code: IOC station code.\n        sensor: Sensor identifier.\n        src_dir: Directory containing transformation JSON files.\n\n    Returns:\n        Parsed transformation model.\n    \"\"\"\n    path = f\"{src_dir}/{ioc_code}_{sensor}.json\"\n    return load_transformation_from_path(path)\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.load_transformation_from_path","level":3,"title":"<code>ioc_cleanup.load_transformation_from_path(path)</code>","text":"<p>Load a transformation definition from a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | PathLike[str]</code> <p>Path to a transformation JSON file describing cleaning rules.</p> required <p>Returns:</p> Type Description <code>Transformation</code> <p>Parsed transformation model.</p> Source code in <code>ioc_cleanup/_tools.py</code> <pre><code>def load_transformation_from_path(path: str | os.PathLike[str]) -&gt; _models.Transformation:\n    \"\"\"\n    Load a transformation definition from a JSON file.\n\n    Parameters:\n        path: Path to a transformation JSON file describing cleaning rules.\n\n    Returns:\n        Parsed transformation model.\n    \"\"\"\n    with open(path) as fd:\n        contents = fd.read()\n    model = _models.Transformation.model_validate_json(contents)\n    return model\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.transform","level":3,"title":"<code>ioc_cleanup.transform(df, transformation=None)</code>","text":"<p>Apply a cleaning transformation to an IOC sea-level time series.</p> <p>The transformation defines the valid time window, dropped timestamps, dropped date ranges, and sensor breakpoints. Bad data is ropped data from the DatFrame;  no offset correction is applied.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Raw IOC sea-level time series. The DataFrame must have <code>ioc_code</code> and <code>sensor</code> entries in its attributes if <code>transformation</code> is not provided.</p> required <code>transformation</code> <code>Transformation | None</code> <p>Cleaning transformation to apply. If not provided, it is loaded automatically using DataFrame attributes.</p> <code>None</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Cleaned time series with metadata stored in <code>DataFrame.attrs</code>.</p> Source code in <code>ioc_cleanup/_tools.py</code> <pre><code>def transform(df: pd.DataFrame, transformation: _models.Transformation | None = None) -&gt; pd.DataFrame:\n    \"\"\"\n    Apply a cleaning transformation to an IOC sea-level time series.\n\n    The transformation defines the valid time window, dropped timestamps,\n    dropped date ranges, and sensor breakpoints. Bad data is ropped data from the DatFrame; \n    no offset correction is applied.\n\n    Parameters:\n        df: Raw IOC sea-level time series. The DataFrame must have\n            `ioc_code` and `sensor` entries in its attributes if\n            `transformation` is not provided.\n        transformation: Cleaning transformation to apply. If not provided,\n            it is loaded automatically using DataFrame attributes.\n\n    Returns:\n        Cleaned time series with metadata stored in `DataFrame.attrs`.\n    \"\"\"\n    attr: int = 1\n    df = df.copy()\n    if transformation is None:\n        transformation = load_transformation(ioc_code=df.attrs[\"ioc_code\"], sensor=df.attrs[\"sensor\"])\n    df = df[transformation.start : transformation.end]  # type: ignore[misc]  # https://stackoverflow.com/questions/70763542/pandas-dataframe-mypy-error-slice-index-must-be-an-integer-or-none\n    for start, end in transformation.dropped_date_ranges:\n        df[start:end] = np.nan  # type: ignore[misc]  # https://stackoverflow.com/questions/70763542/pandas-dataframe-mypy-error-slice-index-must-be-an-integer-or-none\n    if transformation.dropped_timestamps:\n        t_ = pd.DatetimeIndex(transformation.dropped_timestamps)\n        t0 = df.index[0]\n        t1 = df.index[-1]\n        drop_index = np.where(np.logical_and(t_ &gt; t0, t_ &lt; t1))[\n            0\n        ]  # this step is needed to select only timestamps within the DataFrame time window\n        df.loc[t_[drop_index], :] = np.nan\n    df.attrs[\"breakpoints\"] = transformation.breakpoints\n    df.attrs[\"status\"] = \"transformed\"\n    return df\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.clean","level":3,"title":"<code>ioc_cleanup.clean(df, station, sensor)</code>","text":"<p>Clean a raw IOC time series using the corresponding transformation file.</p> <p>This is a convenience wrapper around <code>transform</code> that loads the transformation from disk and returns a single sensor series.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Raw IOC station data.</p> required <code>station</code> <code>str</code> <p>IOC station code.</p> required <code>sensor</code> <code>str</code> <p>Sensor identifier.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>Cleaned sea-level time series for the selected sensor.</p> Source code in <code>ioc_cleanup/_tools.py</code> <pre><code>def clean(df: pd.DataFrame, station: str, sensor: str) -&gt; pd.Series:\n    \"\"\"\n    Clean a raw IOC time series using the corresponding transformation file.\n\n    This is a convenience wrapper around `transform` that loads the\n    transformation from disk and returns a single sensor series.\n\n    Parameters:\n        df: Raw IOC station data.\n        station: IOC station code.\n        sensor: Sensor identifier.\n\n    Returns:\n        Cleaned sea-level time series for the selected sensor.\n    \"\"\"\n    trans = load_transformation_from_path(\"./transformations/\" + station + \"_\" + sensor + \".json\")\n    return transform(df, trans)[sensor]\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#surge-signal-processing","level":2,"title":"Surge &amp; Signal Processing","text":"<p>Utilities for tidal analysis, demeaning, and surge extraction.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.surge","level":3,"title":"<code>ioc_cleanup.surge(ts, opts, rsmp)</code>","text":"<p>Compute the non-tidal (surge) component of a sea-level time series.</p> <p>Tidal constituents are estimated using UTide and reconstructed at the original timestamps. The tidal signal is then subtracted from the observed series.</p> <p>Parameters:</p> Name Type Description Default <code>ts</code> <code>Series</code> <p>Sea-level time series.</p> required <code>opts</code> <code>Mapping[str, Any]</code> <p>UTide solver options.</p> required <code>rsmp</code> <code>int | None</code> <p>Optional resampling interval in minutes. If provided, the series is resampled before tidal analysis.</p> required <p>Returns:</p> Type Description <code>Series</code> <p>Surge (non-tidal residual) time series.</p> Source code in <code>ioc_cleanup/_tools.py</code> <pre><code>def surge(ts: pd.Series, opts: T.Mapping[str, T.Any], rsmp: int | None) -&gt; pd.Series:\n    \"\"\"\n    Compute the non-tidal (surge) component of a sea-level time series.\n\n    Tidal constituents are estimated using UTide and reconstructed at the\n    original timestamps. The tidal signal is then subtracted from the\n    observed series.\n\n    Parameters:\n        ts: Sea-level time series.\n        opts: UTide solver options.\n        rsmp: Optional resampling interval in minutes. If provided, the\n            series is resampled before tidal analysis.\n\n    Returns:\n        Surge (non-tidal residual) time series.\n    \"\"\"\n    ts0 = ts.copy()\n    if rsmp is not None:\n        ts = ts.resample(f\"{rsmp}min\").mean()\n        ts = ts.shift(freq=f\"{rsmp / 2}min\")\n    coef = utide.solve(ts.index, ts, **opts)\n    tidal = utide.reconstruct(ts0.index, coef, verbose=OPTS[\"verbose\"])\n    data = T.cast(np.ndarray, ts0.values - tidal.h)\n    return pd.Series(data=data, index=ts0.index)\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#station-metadata","level":2,"title":"Station Metadata","text":"<p>Access to IOC station metadata and geographic information.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.get_meta","level":3,"title":"<code>ioc_cleanup.get_meta()</code>  <code>cached</code>","text":"<p>Retrieve IOC station metadata with geographic coordinates.</p> <p>Metadata are collected from both the IOC web service and the IOC API and merged into a single GeoDataFrame.</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>GeoDataFrame containing IOC station codes, longitude, latitude,</p> <code>GeoDataFrame</code> <p>and geometry in EPSG:4326.</p> Source code in <code>ioc_cleanup/_searvey.py</code> <pre><code>@functools.cache\ndef get_meta() -&gt; gpd.GeoDataFrame:\n    \"\"\"\n    Retrieve IOC station metadata with geographic coordinates.\n\n    Metadata are collected from both the IOC web service and the IOC API\n    and merged into a single GeoDataFrame.\n\n    Returns:\n        GeoDataFrame containing IOC station codes, longitude, latitude,\n        and geometry in EPSG:4326.\n    \"\"\"\n    meta_web = searvey.get_ioc_stations()\n    meta_api = (\n        pd.read_json(\"http://www.ioc-sealevelmonitoring.org/service.php?query=stationlist&amp;showall=all\")\n        .drop_duplicates()\n        .rename(columns={\"Code\": \"ioc_code\"})\n    )\n\n    merged = pd.merge(\n        meta_web.drop(columns=[\"lon\", \"lat\", \"geometry\"]),\n        meta_api[[\"ioc_code\", \"Lon\", \"Lat\"]].rename(columns={\"Lon\": \"lon\", \"Lat\": \"lat\"}).drop_duplicates(),\n        on=[\"ioc_code\"],\n    )\n    merged = T.cast(\n        gpd.GeoDataFrame,\n        merged.assign(geometry=gpd.points_from_xy(merged.lon, merged.lat, crs=\"EPSG:4326\")),\n    )\n    return merged\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#data-download","level":2,"title":"Data Download","text":"<p>Helpers for downloading and storing IOC raw data.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.download_raw","level":3,"title":"<code>ioc_cleanup.download_raw(ioc_codes, start, end)</code>","text":"<p>Download raw IOC sea-level data for multiple stations.</p> <p>Parameters:</p> Name Type Description Default <code>ioc_codes</code> <code>list[str]</code> <p>List of IOC station codes.</p> required <code>start</code> <code>Timestamp</code> <p>Start timestamp.</p> required <code>end</code> <code>Timestamp</code> <p>End timestamp.</p> required <p>Returns:</p> Type Description <code>dict[str, DataFrame]</code> <p>Dictionary mapping station codes to raw dataframes.</p> Source code in <code>ioc_cleanup/_searvey.py</code> <pre><code>def download_raw(ioc_codes: list[str], start: pd.Timestamp, end: pd.Timestamp) -&gt; dict[str, pd.DataFrame]:\n    \"\"\"\n    Download raw IOC sea-level data for multiple stations.\n\n    Parameters:\n        ioc_codes: List of IOC station codes.\n        start: Start timestamp.\n        end: End timestamp.\n\n    Returns:\n        Dictionary mapping station codes to raw dataframes.\n    \"\"\"\n    no_codes = len(ioc_codes)\n    start_dates = pd.DatetimeIndex([start] * no_codes)\n    end_dates = pd.DatetimeIndex([end] * no_codes)\n    dataframes: dict[str, pd.DataFrame] = searvey._ioc_api._fetch_ioc(\n        station_ids=ioc_codes,\n        start_dates=start_dates,\n        end_dates=end_dates,\n        http_client=None,\n        rate_limit=None,\n        multiprocessing_executor=None,\n        multithreading_executor=None,\n        progress_bar=False,\n    )\n    return dataframes\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.download_year_station","level":3,"title":"<code>ioc_cleanup.download_year_station(station, year, data_folder='./data')</code>","text":"<p>Download and store one year of IOC data for a single station.</p> <p>Data are saved as Parquet files under <code>&lt;data_folder&gt;/&lt;year&gt;/</code>.</p> <p>Parameters:</p> Name Type Description Default <code>station</code> <code>str</code> <p>IOC station code.</p> required <code>year</code> <code>int</code> <p>Year to download.</p> required <code>data_folder</code> <code>str</code> <p>Base directory for storing downloaded data.</p> <code>'./data'</code> Source code in <code>ioc_cleanup/_searvey.py</code> <pre><code>def download_year_station(\n    station: str,\n    year: int,\n    data_folder: str = \"./data\",\n) -&gt; None:\n    \"\"\"\n    Download and store one year of IOC data for a single station.\n\n    Data are saved as Parquet files under `&lt;data_folder&gt;/&lt;year&gt;/`.\n\n    Parameters:\n        station: IOC station code.\n        year: Year to download.\n        data_folder: Base directory for storing downloaded data.\n    \"\"\"\n    data_folder = os.path.abspath(data_folder)\n    year_folder = os.path.join(data_folder, str(year))\n    os.makedirs(year_folder, exist_ok=True)\n    try:\n        start = pd.Timestamp(f\"{year}-01-01\")\n        end = pd.Timestamp(f\"{year}-12-31T23:59:59\")\n        dict_df = download_raw([station], start, end)\n        df = dict_df[station]\n        if not df.empty:\n            df.to_parquet(f\"{year_folder}/{station}.parquet\")\n            logger.info(f\"  Saved {station} for {year}\")\n    except Exception as e:\n        logger.error(f\"Error for {station} in {year}: {e}\")\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#data-loading","level":2,"title":"Data Loading","text":"<p>Utilities for loading archived IOC data from disk.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.load_station","level":3,"title":"<code>ioc_cleanup.load_station(station, data_dir=Path('./data'), start_year=2011, end_year=2024)</code>","text":"<p>Load multi-year IOC data for a station from local Parquet files.</p> <p>Parameters:</p> Name Type Description Default <code>station</code> <code>str</code> <p>IOC station code.</p> required <code>data_dir</code> <code>Path</code> <p>Base directory containing yearly Parquet files.</p> <code>Path('./data')</code> <code>start_year</code> <code>int</code> <p>First year to load (inclusive).</p> <code>2011</code> <code>end_year</code> <code>int</code> <p>Last year to load (exclusive).</p> <code>2024</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Concatenated DataFrame containing the available station data.</p> <code>DataFrame</code> <p>Returns an empty DataFrame if no data are found.</p> Source code in <code>ioc_cleanup/_searvey.py</code> <pre><code>def load_station(\n    station: str,\n    data_dir: Path = Path(\"./data\"),\n    start_year: int = 2011,\n    end_year: int = 2024,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Load multi-year IOC data for a station from local Parquet files.\n\n    Parameters:\n        station: IOC station code.\n        data_dir: Base directory containing yearly Parquet files.\n        start_year: First year to load (inclusive).\n        end_year: Last year to load (exclusive).\n\n    Returns:\n        Concatenated DataFrame containing the available station data.\n        Returns an empty DataFrame if no data are found.\n    \"\"\"\n    dfs = []\n    for year in range(start_year, end_year):\n        path = data_dir / str(year) / f\"{station}.parquet\"\n        if not os.path.exists(path):\n            continue\n        df = pd.read_parquet(path)\n        if df.empty:\n            continue\n        dfs.append(df)\n\n    if dfs:\n        return pd.concat(dfs)\n    else:\n        logger.error(f\"No data found for station {station}\")\n        return pd.DataFrame()\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#models","level":2,"title":"Models","text":"<p>Core data models used by the cleaning workflow.</p>","path":["Reference","Python API"],"tags":[]},{"location":"reference/python-api/#ioc_cleanup.Transformation","level":3,"title":"<code>ioc_cleanup.Transformation</code>","text":"<p>               Bases: <code>BaseModel</code></p> Source code in <code>ioc_cleanup/_models.py</code> <pre><code>class Transformation(pydantic.BaseModel):\n    ioc_code: str\n    sensor: str\n    notes: str = \"\"\n    skip: bool = False\n    wip: bool = False\n    start: datetime.datetime\n    end: datetime.datetime\n    high: float | None = None\n    low: float | None = None\n    dropped_date_ranges: list[tuple[datetime.datetime, datetime.datetime]] = []\n    dropped_timestamps: list[datetime.datetime] = []\n    breakpoints: list[datetime.datetime] = []\n    tsunami: list[tuple[datetime.datetime, datetime.datetime]] = []\n</code></pre>","path":["Reference","Python API"],"tags":[]},{"location":"workflows/dashboard/","level":1,"title":"Interactive Cleaning Dashboard","text":"","path":["Dashboard","Interactive Cleaning Dashboard"],"tags":[]},{"location":"workflows/dashboard/#running-the-dashboard","level":2,"title":"Running the dashboard","text":"<p><pre><code>python -mpanel serve dashboard/cleanup_dashboard.py\n</code></pre> </p>","path":["Dashboard","Interactive Cleaning Dashboard"],"tags":[]},{"location":"workflows/dashboard/#station-dropdown-list","level":2,"title":"Station dropdown list","text":"<p>Stations are discovered automatically from the JSONs in: <pre><code>./transformations/&lt;ioc_code&gt;_&lt;sensor&gt;.json\n</code></pre></p>","path":["Dashboard","Interactive Cleaning Dashboard"],"tags":[]},{"location":"workflows/dashboard/#error-handling","level":2,"title":"Error handling","text":"<p>If a JSON file contains a syntax error or invalid field, the dashboard will show:</p> <p></p>","path":["Dashboard","Interactive Cleaning Dashboard"],"tags":[]},{"location":"workflows/dashboard/#dark-mode","level":2,"title":"Dark mode","text":"<p>You can activate dark mode by clicking on the top right switch</p> <p></p>","path":["Dashboard","Interactive Cleaning Dashboard"],"tags":[]}]}
